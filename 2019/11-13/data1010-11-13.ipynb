{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Statistics and Markov Chains\n",
    "\n",
    "#### *13 November 2019*\n",
    "\n",
    "#### *DATA 1010*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "using Plots, Random, LinearAlgebra, Statistics, Distributions, SymPy, SpecialFunctions, Interact\n",
    "gr(fontfamily = \"Palatino\", legend=false)\n",
    "Random.seed!(1234);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our study statistics so far has reflected an approach to statistics called 'frequentism': data is presumed to come from a fixed, unknown distribution that we seek to draw conclusions about.\n",
    "\n",
    "Bayesian statistics relaxes this assumption by applying the same treatment to the distribution parameters that we normally apply to unknown entities: we think of them as **random**, described by a probability distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "\n",
    "(a) Consider a coin that an acquaintance is about to flip to determine who pays for lunch. If you had to posit a single number to represent the heads probability of that coin, what number would you choose?\n",
    "\n",
    "(b) Perhaps it's overconfident to settle on a single value for the coin's heads probability. Suppose you're willing to represent the heads probability as a random variable with some distribution on $[0,1]$. Given what you know about coins, what distribution would you posit for this random variable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Solution*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Problem 2\n",
    "\n",
    "Your answer to Problem 1 is called a **prior distribution**. As we will soon see, some distributions make especially nice priors. For the coin flip problem, we'll look at the **Beta** distribution, whose PDF on $[0,1]$ is\n",
    "\n",
    "$$\n",
    "p\\mapsto \\frac{1}{B(\\alpha, \\beta)} p^{\\alpha - 1} (1 - p)^{\\beta - 1}, \n",
    "$$\n",
    "\n",
    "where $B(\\alpha, \\beta)$ is a normalization constant (in other words, $B(\\alpha, \\beta)$ is whatever value it has to be to ensure the function integrates to 1 over the unit interval. WolframAlpha can [express its value](https://www.wolframalpha.com/input/?i=integrate%28p%5E%28α-1%29*%281-p%29%5E%28β-1%29%2C%28p%2C0%2C1%29%29) in terms of another special function, but you can use `beta(α, β)` to get it from `SpecialFunctions` in Julia). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the Beta density for a variety of different (integer) choices for $\\alpha$ and $\\beta$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Solution*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens when $\\alpha$ and $\\beta$ are equal and large? What about when they're equal and small? When one is significantly larger than the other?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Solution*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Problem 3\n",
    "\n",
    "Now let's see what's cool about the Beta distribution. Suppose that our prior for a particular coin is some beta distribution with parameters $\\alpha$ and $\\beta$. Then we observe $N$ outcomes from flipping the coin, of which $H$ are heads and $T$ are tails. Let's call this vector of results $x$. How should we update the probability distribution representing our belief about the coin's heads probability?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: recall Bayes theorem, which for probability densities says that\n",
    "$$\n",
    "\\overbrace{f(p|x)}^{\\text{posterior}} =\n",
    "\\frac{\\overbrace{f(x|p)}^{\\text{likelihood}}\n",
    "\\overbrace{f(p)}^{\\text{prior}}}\n",
    "{\\underbrace{f(x)}_{\\text{marginal}}}.\n",
    "$$\n",
    "(Note that these $f$'s are different densities; $f(x)$ is short for $f_X(x)$, $f(p|x)$ for $f_{P|X}(p|x)$, and so on. Using such abbreviations is a common practice for helping keep the notation clean.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Solution*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4\n",
    "\n",
    "Suppose that a wingnut factory has has produced wingnuts succesfully in the past, to the point that your estimate for the probability that a wingnut from the factory is non-defective is Beta distributed with parameters $\\alpha = 80$ and $\\beta=3$. Suppose that you get a dozen wingnuts from the factory, and 6 of them turn out to be defective. \n",
    "\n",
    "(a) Produce a Bayesian point estimate of the non-defectiveness probability for a wingnut made by that factory, as well as a 95% Bayesian posterior interval (like a confidence interval from frequentist statistics). (Note: you'll have to think of a good way to boil the Bayesian posterior distribution down to a single value, or down to an interval of values.)\n",
    "\n",
    "(b) Critique this analysis. Why might you be more skeptical of the wingnut factory than the Bayesian calculations would suggest?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Solution*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5\n",
    "\n",
    "We call the Beta distribution a **conjugate prior** for the coin flip problem. While conjugate priors are elegant, they aren't always applicable, since our prior distribution might happen to not be in a conjugate family, or we might not be able to come up with a conjugate family for a given problem. So more general techniques are called for. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, suppose we have data $x$ and would like to obtain the posterior mean for\n",
    "a parameter $\\theta \\in [1,2]$. We will assume\n",
    "$f(\\theta) = \\frac{1}{\\log(4)-1}\\log(\\theta)$ and that\n",
    "$f(x|\\theta) \\sim \\operatorname{Normal}(\\theta,1)$. \n",
    "\n",
    "(a) Plot both of these distributions (the latter for a few values of $\\theta$). \n",
    "\n",
    "(b) Derive a formula for the posterior mean, and note that it cannot be computed analytically. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Solution*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 6\n",
    "\n",
    "How could we evaluate the integrals from Problem 5 efficiently and accurately? Explain why this *wouldn't* work if our data were very high dimensional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Solution*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 7\n",
    "\n",
    "One way to sample from a distribution on a set $\\Omega$ is to put a particle somewhere in $\\Omega$ and have it move around $\\Omega$ randomly according to some specified rules. Let's start with a  simple example where $\\Omega$ has four elements, say $A$, $B$, $C$, and $D$ (even though we could sample from a distribution on $\\Omega$ using the inverse CDF trick in this case). \n",
    "\n",
    "<img src=\"markov-chain.svg\" width=600px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Define a matrix whose $(i,j)$th element is equal to the probability of moving to the $j$th node next given that you're currently on the $i$th node (these values are indicated in the yellow labels on the arrows in the figure above). This is called the **transition matrix**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Solution*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Simulate 10,000 runs of 100 steps of this process, each starting from A. Repeat, but starting from B. Based on this experiment, what can you say about distribution of the state at step 100?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Solution*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Show that the probability you're in state $j$ after starting from state $i$ and taking $n$ steps is equal to the $(i,j)$th entry of $P^n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Solution*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Calculate $P^n$ for several values of $n$. What happens as $n\\to\\infty$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Solution*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) The distribution you found in the previous part is called the *stationary* distribution of the transition matrix $P$. Show by computation that you end up with the same distribution if you compute the eigenvector of $P'$ whose entries are all positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Solution*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Problem 8 (Challenge problem)\n",
    "\n",
    "Consider the following example as a case in which the Bayesian approach is more useful than the frequentist approach.\n",
    "\n",
    "(a) Suppose that we know the distribution of our underlying sample space. We have to take an action $a$, given the data $\\mathbf{x}$. This action may be a classification or a regression, in which case we incur a loss $L(y,a(\\mathbf{x})) = \\mathbb{I}(y \\neq a(\\mathbf{x}))$ and squared loss $L(y,a(\\mathbf{x})) = (y - a(\\mathbf{x}))^2$.\n",
    "\n",
    "Our goal is to devise a decision procedure from our data to the action space $\\delta: X \\mapsto A$ that optimally specifies the action for each possible option. How should we formulate this $\\delta$ as a function of $x$?\n",
    "\n",
    "(b) Suppose that we ascribe a distribution $f_\\Theta(\\theta)$ to $\\theta$, and we updated our posterior distribution as $f(\\theta| \\mathbf{x})$. As we optimize for the decision strategy $\\delta$, we need to estimate how the $\\delta$ will on average behave since each time the sample from the distribution is different. Write the distribution for our data $f_{X|\\Theta}(x|\\theta)$. Formalize this expectation--we call this expected loss $\\textbf{risk}$.\n",
    "\n",
    "(c) The trouble is, in a frequentist setting, we do not assume knowledge of the parameters controlling the underlying distribution. As a result, we have no way of defining $\\delta: X\\to A$ according to the distribution because the distribution $X$ is not defined. Explain why this would be a problem for estimating the expectation above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": "39b3018b-a7c1-4bd5-9207-9476de022aae",
   "lastKernelId": "202c28be-095e-41af-b846-c2239aa4ee3b"
  },
  "jupytext": {
   "formats": "ipynb"
  },
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
