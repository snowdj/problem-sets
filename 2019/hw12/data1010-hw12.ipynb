{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["## Homework 12\n", "\n", "#### *DATA 1010*"]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\u001b[32m\u001b[1mActivating\u001b[22m\u001b[39m environment at `~/Google Drive/DSI/Masters Program/DATA 1010/DATA1010-2019/problem-sets/hw12/Project.toml`\n"]}], "source": ["import Pkg; Pkg.activate(\".\")"]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": ["\u250c Info: [Turing]: global PROGRESS is set as false\n", "\u2514 @ Turing /Users/sswatson/.julia/packages/Turing/xFzfF/src/Turing.jl:23\n"]}], "source": ["using Random, CSV, Turing, Distributions, MCMCChains, Plots, StatsPlots, StatsFuns\n", "Turing.turnprogress(false);\n", "Random.seed!(123);"]}, {"cell_type": "markdown", "metadata": {}, "source": ["---\n", "\n", "## Problem 1\n", "\n", "Consider two probability density functions, $f_1(x)$ and $f_2(x)$. Assume that we have $N$ observations $x_1,\\cdots,x_N$ drawn from a mixture of these **known** densities:\n", "$$ \\pi f_1(x) + (1-\\pi) f_2(x) $$\n", "Write down the E and M steps you would use to estimate the proportion $\\pi$, given the dataset.\n", "\n", "*Hint*: Use a hidden state variable $z_i$ to indicate that data point $x_i$ belongs to $f_1$."]}, {"cell_type": "markdown", "metadata": {}, "source": ["---\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Problem 2 (Bayesian Logistic Regression)\n", "\n", "Recall logistic regression, where we find coefficients $\\mathbf{\\beta}, \\alpha$ to predict label the $y_i$ given input features $\\mathbf{x_i}$:\n", "$$ \\mathbb{P}(y_i = 1|\\mathbf{x_i}) = \\sigma(\\boldsymbol{\\beta}'\\mathbf{x_i} + \\alpha)$$\n", "\n", "Here, we develop the Bayesian counterpart to obtain the full posterior over the coefficients: $\\mathbb{P}(\\mathbf{\\beta}|\\mathcal{D})$, where data $\\mathcal{D}$ consists of all training observations. Unlike linear regression, there is no convenient conjugate prior for logistic regression, so we use MCMC with `Turing.jl`"]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [{"data": {"text/html": ["<table class=\"data-frame\"><thead><tr><th></th><th>admit</th><th>gre</th><th>gpa</th><th>rank</th></tr><tr><th></th><th>Int64</th><th>Int64</th><th>Float64</th><th>Int64</th></tr></thead><tbody><p>6 rows \u00d7 4 columns</p><tr><th>1</th><td>0</td><td>380</td><td>3.61</td><td>3</td></tr><tr><th>2</th><td>1</td><td>660</td><td>3.67</td><td>3</td></tr><tr><th>3</th><td>1</td><td>800</td><td>4.0</td><td>1</td></tr><tr><th>4</th><td>1</td><td>640</td><td>3.19</td><td>4</td></tr><tr><th>5</th><td>0</td><td>520</td><td>2.93</td><td>4</td></tr><tr><th>6</th><td>1</td><td>760</td><td>3.0</td><td>2</td></tr></tbody></table>"], "text/latex": ["\\begin{tabular}{r|cccc}\n", "\t& admit & gre & gpa & rank\\\\\n", "\t\\hline\n", "\t& Int64 & Int64 & Float64 & Int64\\\\\n", "\t\\hline\n", "\t1 & 0 & 380 & 3.61 & 3 \\\\\n", "\t2 & 1 & 660 & 3.67 & 3 \\\\\n", "\t3 & 1 & 800 & 4.0 & 1 \\\\\n", "\t4 & 1 & 640 & 3.19 & 4 \\\\\n", "\t5 & 0 & 520 & 2.93 & 4 \\\\\n", "\t6 & 1 & 760 & 3.0 & 2 \\\\\n", "\\end{tabular}\n"], "text/plain": ["6\u00d74 DataFrame\n", "\u2502 Row \u2502 admit \u2502 gre   \u2502 gpa     \u2502 rank  \u2502\n", "\u2502     \u2502 \u001b[90mInt64\u001b[39m \u2502 \u001b[90mInt64\u001b[39m \u2502 \u001b[90mFloat64\u001b[39m \u2502 \u001b[90mInt64\u001b[39m \u2502\n", "\u251c\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n", "\u2502 1   \u2502 0     \u2502 380   \u2502 3.61    \u2502 3     \u2502\n", "\u2502 2   \u2502 1     \u2502 660   \u2502 3.67    \u2502 3     \u2502\n", "\u2502 3   \u2502 1     \u2502 800   \u2502 4.0     \u2502 1     \u2502\n", "\u2502 4   \u2502 1     \u2502 640   \u2502 3.19    \u2502 4     \u2502\n", "\u2502 5   \u2502 0     \u2502 520   \u2502 2.93    \u2502 4     \u2502\n", "\u2502 6   \u2502 1     \u2502 760   \u2502 3.0     \u2502 2     \u2502"]}, "execution_count": 3, "metadata": {}, "output_type": "execute_result"}], "source": ["grad_data = CSV.read(\"grad_admission.csv\")\n", "first(grad_data, 6)"]}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [], "source": ["grad_data.gre = (grad_data.gre .- mean(grad_data.gre)) ./ std(grad_data.gre)\n", "grad_data.gpa = (grad_data.gpa .- mean(grad_data.gpa)) ./ std(grad_data.gpa)\n", "\n", "grad_data = grad_data[shuffle(1:size(grad_data, 1)),:];\n", "\n", "train_test_split_index = Int(round(size(grad_data, 1) * 0.7))\n", "train = grad_data[1:train_test_split_index, :]\n", "test = grad_data[(train_test_split_index+1):end, :]\n", "\n", "train_label = train[:,:admit];\n", "test_label = test[:,:admit];\n", "\n", "train = train[:,[:gre, :gpa, :rank]];\n", "test = test[:,[:gre, :gpa, :rank]];"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Write a Turing.jl model called `logistic_regression` which gives priors of $N(0, \\sigma)$ to `intercept`, `gre`, `gpa`, and `rank`. "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["@model logistic_regression(x, y, n, \u03c3) = begin\n", "    \n", "\n", "end;"]}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [{"data": {"text/plain": ["2-element Array{ChainDataFrame,1}\n", "\n", "Summary Statistics\n", ". Omitted printing of 1 columns\n", "\u2502 Row \u2502 parameters \u2502 mean     \u2502 std       \u2502 naive_se    \u2502 mcse       \u2502 ess     \u2502\n", "\u2502     \u2502 \u001b[90mSymbol\u001b[39m     \u2502 \u001b[90mFloat64\u001b[39m  \u2502 \u001b[90mFloat64\u001b[39m   \u2502 \u001b[90mFloat64\u001b[39m     \u2502 \u001b[90mFloat64\u001b[39m    \u2502 \u001b[90mAny\u001b[39m     \u2502\n", "\u251c\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n", "\u2502 1   \u2502 gpa        \u2502 0.321881 \u2502 0.356509  \u2502 0.00531453  \u2502 0.0534671  \u2502 18.0723 \u2502\n", "\u2502 2   \u2502 gre        \u2502 0.59765  \u2502 0.0950642 \u2502 0.00141713  \u2502 0.0111314  \u2502 18.0723 \u2502\n", "\u2502 3   \u2502 intercept  \u2502 2.65669  \u2502 0.130045  \u2502 0.0019386   \u2502 0.0169787  \u2502 18.0723 \u2502\n", "\u2502 4   \u2502 rank       \u2502 0.269729 \u2502 0.0652298 \u2502 0.000972388 \u2502 0.00895466 \u2502 18.0723 \u2502\n", "\n", "Quantiles\n", "\n", "\u2502 Row \u2502 parameters \u2502 2.5%      \u2502 25.0%     \u2502 50.0%    \u2502 75.0%    \u2502 97.5%    \u2502\n", "\u2502     \u2502 \u001b[90mSymbol\u001b[39m     \u2502 \u001b[90mFloat64\u001b[39m   \u2502 \u001b[90mFloat64\u001b[39m   \u2502 \u001b[90mFloat64\u001b[39m  \u2502 \u001b[90mFloat64\u001b[39m  \u2502 \u001b[90mFloat64\u001b[39m  \u2502\n", "\u251c\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n", "\u2502 1   \u2502 gpa        \u2502 -0.160595 \u2502 -0.160595 \u2502 0.445086 \u2502 0.688054 \u2502 0.688054 \u2502\n", "\u2502 2   \u2502 gre        \u2502 0.515744  \u2502 0.515744  \u2502 0.570257 \u2502 0.689438 \u2502 0.689438 \u2502\n", "\u2502 3   \u2502 intercept  \u2502 2.51657   \u2502 2.51657   \u2502 2.67181  \u2502 2.79141  \u2502 2.79141  \u2502\n", "\u2502 4   \u2502 rank       \u2502 0.201209  \u2502 0.201209  \u2502 0.256444 \u2502 0.346412 \u2502 0.346412 \u2502\n"]}, "execution_count": 5, "metadata": {}, "output_type": "execute_result"}], "source": ["# Retrieve the number of observations.\n", "n = size(train, 1)\n", "\n", "# Sample using HMC\n", "chain = mapreduce(c -> sample(logistic_regression(train, train_label, n, 1), HMC(0.05, 10), 1500),\n", "    chainscat,\n", "    1:3\n", ")\n", "\n", "describe(chain)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["---\n", "\n", "## Problem 3 (Simpson\u2019s Paradox)\n", "\n", "Consider the following classic example given by Edward Simpson in 1951.\n", "\n", "700 patients were given access to a drug the effectiveness of which we would like to study. A total of 350 patients chose to take the drug and 350 didn\u2019t. The result is given below:\n", "\n", "|Categories            | Drug                           | No Drug   |\n", "|---------------    |---------------------|--------------------------------|\n", "| Men           | 81 out of 87 (93%)             | 234 out of 270 recovered (87%) |   \n", "| Women         | 192 out of 263 recovered (73%) | 55 out of 80 recovered (69%)   |\n", "| Combined data | 273 out of 350 recovered (78%) | 289 out of 350 recovered (83%) |\n", "\n", "(a) Not controlling for sex, describe the overall trend of taking the drug.\n", "\n", "(b) Describe the overall trend of taking the drug conditioned on sex.\n", "\n", "(c) Match the following English sentences to its corresponding mathematical statement in the list below. Note that one of the mathematical statements will not have a match. Here men are $Z=0$, women are $Z=1$, non-recovery is $Y=0$, and recovery is $Y=1$, and non-treatment is $X=0$ and treatment is $X=1$.\n", "\n", "(i) The drug is beneficial for men.  \n", "(ii) The drug is beneficial for women.  \n", "(iii) The drug is beneficial overall.\n", "\n", "(I) $\\mathbb{P}(Y=1 | X=1) > \\mathbb{P}(Y=1 | X=0)$  \n", "(II) $\\mathbb{P}(C_1 = 1) > \\mathbb{P}(C_1 = 0)$  \n", "(III) $\\mathbb{P}(C_1 = 1 | Z = 1) > \\mathbb{P}(C_1 = 0 | Z = 1)$  \n", "(IV) $\\mathbb{P}(C_1 = 1 | Z = 0) > \\mathbb{P}(C_1 = 0 | Z = 0)$\n", "\n", "(d) Show mathematically that if a drug is beneficial for each subpopulation in a partition of the overall population, then it is beneficial overall. (Hint: you will want to use the formulation of \"beneficial\" from part (c). "]}, {"cell_type": "markdown", "metadata": {}, "source": ["---\n", "\n", "## Problem 4\n", "\n", "Consider the following statement from an advertisement. \n", "\n", "\u2018In this town we observe that those who take soy isoflavone supplements have improved cognitive performance. Thus, for anyone looking to improve their cognitive performance, they should consider taking soy isoflavone.\u2019\n", "\n", "Identify the problematic causal inference in this statement. Identify whether each statement strengthens or weakens the claim (or neither).\n", "\n", "\n", "a) The alleged cause and effect are both effects of some common cause.\n", "\n", "b) The cause and effect are flipped; the alleged cause is the effect and vice versa.\n", "\n", "c) The presence of the cause in a relatively large population does not coincide with the detection of the effect. \n", "\n", "d) The presence of the effect has been identified in a large population but not the cause.\n", "\n", "e) A possible confounder for this effect has been ruled out."]}, {"cell_type": "markdown", "metadata": {}, "source": ["---\n", "\n", "## Problem 5\n", "\n", "Suppose we want to evaluate the impact of the National Supported Work (NSW) Demonstration, a labor training program on real earnings in 1978. Our dataset, from [LaLonde (1986)](https://www.jstor.org/stable/1806062), consists of measurements of age, years of schooling, ethnicity, marital status and earnings."]}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [{"data": {"text/html": ["<table class=\"data-frame\"><thead><tr><th></th><th>data_id</th><th>treat</th><th>age</th><th>education</th><th>black</th><th>hispanic</th><th>married</th><th>nodegree</th><th>re75</th></tr><tr><th></th><th>String</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Float64</th></tr></thead><tbody><p>6 rows \u00d7 10 columns (omitted printing of 1 columns)</p><tr><th>1</th><td>Lalonde Sample</td><td>0</td><td>18</td><td>9</td><td>0</td><td>1</td><td>0</td><td>1</td><td>2684.91</td></tr><tr><th>2</th><td>Lalonde Sample</td><td>0</td><td>33</td><td>11</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0.0</td></tr><tr><th>3</th><td>Lalonde Sample</td><td>0</td><td>19</td><td>9</td><td>1</td><td>0</td><td>0</td><td>1</td><td>1537.93</td></tr><tr><th>4</th><td>Lalonde Sample</td><td>0</td><td>20</td><td>9</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0.0</td></tr><tr><th>5</th><td>Lalonde Sample</td><td>1</td><td>46</td><td>8</td><td>1</td><td>0</td><td>1</td><td>1</td><td>0.0</td></tr><tr><th>6</th><td>Lalonde Sample</td><td>1</td><td>31</td><td>13</td><td>0</td><td>0</td><td>0</td><td>0</td><td>5498.35</td></tr></tbody></table>"], "text/latex": ["\\begin{tabular}{r|cccccccccc}\n", "\t& data\\_id & treat & age & education & black & hispanic & married & nodegree & re75 & \\\\\n", "\t\\hline\n", "\t& String & Int64 & Int64 & Int64 & Int64 & Int64 & Int64 & Int64 & Float64 & \\\\\n", "\t\\hline\n", "\t1 & Lalonde Sample & 0 & 18 & 9 & 0 & 1 & 0 & 1 & 2684.91 & $\\dots$ \\\\\n", "\t2 & Lalonde Sample & 0 & 33 & 11 & 1 & 0 & 0 & 1 & 0.0 & $\\dots$ \\\\\n", "\t3 & Lalonde Sample & 0 & 19 & 9 & 1 & 0 & 0 & 1 & 1537.93 & $\\dots$ \\\\\n", "\t4 & Lalonde Sample & 0 & 20 & 9 & 1 & 0 & 0 & 1 & 0.0 & $\\dots$ \\\\\n", "\t5 & Lalonde Sample & 1 & 46 & 8 & 1 & 0 & 1 & 1 & 0.0 & $\\dots$ \\\\\n", "\t6 & Lalonde Sample & 1 & 31 & 13 & 0 & 0 & 0 & 0 & 5498.35 & $\\dots$ \\\\\n", "\\end{tabular}\n"], "text/plain": ["6\u00d710 DataFrame. Omitted printing of 4 columns\n", "\u2502 Row \u2502 data_id        \u2502 treat \u2502 age   \u2502 education \u2502 black \u2502 hispanic \u2502\n", "\u2502     \u2502 \u001b[90mString\u001b[39m         \u2502 \u001b[90mInt64\u001b[39m \u2502 \u001b[90mInt64\u001b[39m \u2502 \u001b[90mInt64\u001b[39m     \u2502 \u001b[90mInt64\u001b[39m \u2502 \u001b[90mInt64\u001b[39m    \u2502\n", "\u251c\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n", "\u2502 1   \u2502 Lalonde Sample \u2502 0     \u2502 18    \u2502 9         \u2502 0     \u2502 1        \u2502\n", "\u2502 2   \u2502 Lalonde Sample \u2502 0     \u2502 33    \u2502 11        \u2502 1     \u2502 0        \u2502\n", "\u2502 3   \u2502 Lalonde Sample \u2502 0     \u2502 19    \u2502 9         \u2502 1     \u2502 0        \u2502\n", "\u2502 4   \u2502 Lalonde Sample \u2502 0     \u2502 20    \u2502 9         \u2502 1     \u2502 0        \u2502\n", "\u2502 5   \u2502 Lalonde Sample \u2502 1     \u2502 46    \u2502 8         \u2502 1     \u2502 0        \u2502\n", "\u2502 6   \u2502 Lalonde Sample \u2502 1     \u2502 31    \u2502 13        \u2502 0     \u2502 0        \u2502"]}, "execution_count": 6, "metadata": {}, "output_type": "execute_result"}], "source": ["la_londe = CSV.read(\"lalonde.csv\")\n", "la_londe = la_londe[shuffle(1:size(la_londe, 1)),:];\n", "first(la_londe, 6)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["a) Compare features (age, years of education, etc.) between individuals that received treatment (`treat = 1`) and those who are in the control group (`treat = 0`). What do you observe? What might be the confounding factors in our analysis?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["To mitigate (but not entirely eliminate) the effect of confounding factors, we can match data between treatment and control pairs as follows:\n", "\n", "i. Define a distance measure between feature vectors.\n", "\n", "ii. Select a subset from the treatment and control groups which are close.\n", "\n", "iii. Evaluate quality of matching\n", "\n", "iv. Perform analysis on the matched set.\n", "\n", "b) Consider the *Mahalanobis distance* between observations $x_i$ and $x_j$, defined as : $D_{ij} = (x_i - x_j)^T\\Sigma^{-1}(x_i - x_j)$, where $\\Sigma$ is the covariance matrix estimated from the data. Compute $D_{ij}$ using age, education and re75 (real income in 1975). "]}, {"cell_type": "markdown", "metadata": {}, "source": ["c) The *propensity score distance* is defined as $D_{ij} = |\\pi_i - \\pi_j|$, where $\\pi_i = \\mathbb{P}(\\text{treat}=1|x_i)$ is the probability of being in the treatment group for observation $x_i$. Compute propensity scores for the LaLonde dataset and extract a matching set."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}], "metadata": {"jupytext": {"formats": "ipynb"}, "kernelspec": {"display_name": "Julia 1.2.0", "language": "julia", "name": "julia-1.2"}, "language_info": {"file_extension": ".jl", "mimetype": "application/julia", "name": "julia", "version": "1.2.0"}}, "nbformat": 4, "nbformat_minor": 4}