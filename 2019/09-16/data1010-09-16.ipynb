{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Arithmetic and Numerical Error\n",
    "\n",
    "#### *16 September 2019*\n",
    "#### *DATA 1010*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Arithmetic\n",
    "\n",
    "Arbitrary real numbers can't be represented in a computer. Indeed, if we choose a fixed amount of memory like 64 bits, then only $2^{64}$ real numbers can be represented. The figure below shows the set of (nonnegative) numbers which are chosen for the `Float64` system, which is the most common system for real arithmetic in modern computers.\n",
    "\n",
    "<img src=\"float64.svg\" style=\"width: 100%; min-width: 800px\">\n",
    "\n",
    "\n",
    "The numbers are much more densely packed around zero because we want to be able to represent numbers with a high precision *relative to the size of the number*, and this requires that gaps between representable numbers be smaller close to zero.\n",
    "\n",
    "We interpret a string of 64 bits as a Float64 as follows: the first bit is called the *sign bit*, and it indicates whether the number is positive or negative. The next 11 bits define the **exponent**, which tells us which two powers of 2 we're between in the picture above. Finally, the last 52 bits form the **mantissa**, which tells us which tick we're on between successive powers of 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = bitstring(0.5^1022 + 14 * 0.5^1073)\n",
    "s[1], s[2:12], s[13:end]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Problem 1\n",
    "\n",
    "Show that $x- y= 0$ if and only if $x = y$ (where $x$ and $y$ are `Float64`s and the subtraction is a `Float64` operation). Show that this is *not* the case in the variant of the `Float64` system which lacks subnormal numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Solution.* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Problem 2\n",
    "\n",
    "Select the numbers which are exactly representable as a `Float64`:\n",
    "\n",
    "$$\\quad 2^{1024}, \\quad \\frac{4}{3}, \\quad -2^{-1074}, \\quad \\frac{3}{8}, \\quad 0.0, \\quad 1.5, \\quad 0.8$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Solution*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "### Problem 3\n",
    "\n",
    "In Julia, the function `nextfloat` returns the next largest representable value. Predict the values returned by the following lines of code, and then run them to confirm your predictions.\n",
    "\n",
    "```julia\n",
    "log2(nextfloat(15.0)-15.0)\n",
    "log2(nextfloat(0.0))\n",
    "log2(1.0 - prevfloat(1.0))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log2(1.0-prevfloat(1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Problem 4\n",
    "\n",
    "Investigate the rounding behavior when the result of a calculation is exactly between two representable values. Define ```系 = 0.5^52``` and check whether ```1.0 + 0.5系 == 1.0```. Repeat with 1.5 in place of 0.5 (and appropriate changes made to the right-hand side). What does the rounding rule appear to be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "系 = 0.5^52\n",
    "1.0 + 0.5系 == 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Problem 5\n",
    "\n",
    "Between which two consecutive powers of 2 are the (Float64) representable numbers exactly the integers in that range? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Solution*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Condition number\n",
    "\n",
    "### Problem 6\n",
    "\n",
    "Consider a function $S: \\mathbb{R} \\to \\mathbb{R}$. If the input changes from $a$ to $a + \\Delta a$ for some small value $\\Delta a$, then the output changes to approximately $S(a) + \\frac{\\operatorname{d}}{\\operatorname{d} a}S(a) \\, \\Delta a$. Calculate the ratio of the relative change in the output to the relative change in the input, and show that you get\n",
    "$$\n",
    "\\frac{a\\frac{\\operatorname{d}}{\\operatorname{d} a}S(a)}{S(a)}. \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Problem 7\n",
    "\n",
    "The expression $\\frac{a\\frac{\\operatorname{d}}{\\operatorname{d} a}S(a)}{S(a)}$ is called the **condition number** of $S$. (We can also discuss the condition number of a *problem* which maps initial data $a$ to the solution $S(a)$).\n",
    "\n",
    "Show that the condition number of $a\\mapsto a^n$ is constant, for any $n \\in \\mathbb{R}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Solution*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Problem 8\n",
    "\n",
    "Show that the condition number of the function $a\\mapsto a - 1$ is very large for values of $a$ near 1.\n",
    "\n",
    "*Solution*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Well-conditioned problems and stable algorithms\n",
    "\n",
    "If the condition number of a problem is very large, then small errors in the problem data lead to large changes in the result. A problem with large condition number is said to be **ill-conditioned**.\n",
    "\n",
    "An algorithm used to solve a problem is **stable** if it is approximately as accurate as the condition number of the problem allows. In other words, an algorithm is *unstable* if the answers it produces have relative error many times larger than $\\kappa \\epsilon_{\\text{mach}}$.\n",
    "\n",
    "### Problem 9\n",
    "\n",
    "Find a stable algorithm for evaluating the function $f(x) = \\sqrt{1+x} - 1$, and compare the stable algorithm to the order-of-operations algorithm implemented in the function $f$ below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "f(x) = sqrt(1+x) - 1\n",
    "# f_stable(x) = \n",
    "# f(1e-12), f_stable(1e-12), f(big(10)^-12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Problem 10\n",
    "\n",
    "<img src=\"svd2.svg\" style=\"float: right; width: 50%; min-width: 400px\">\n",
    "\n",
    "We define the condition number of a matrix $A$ to the **maximum** condition number of $\\mathbf{x}\\mapsto A\\mathbf{x}$, over all values of $\\mathbf{x}$ and all possible directions for the error vector.\n",
    "\n",
    "Show that the condition number of a matrix $A$ is equal to the ratio of its largest and smallest singular values.\n",
    "\n",
    "Hint: consider two vectors on the domain side of the picture: $\\mathbf{v}$ and $\\mathbf{v}+\\mathbf{e}$ (where $\\mathbf{e}$ represents error). If we want the relative error to be magnified as much as possible under the transformation $A$, we want the error to be magnified as much as possible while the norm of $\\mathbf{v}$ is shrunk as much as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Challenge Problem\n",
    "\n",
    "Calculating inverse square roots is a very common task in graphics-intensive settings like video games. In the late 1990's, the following algorithm for approximating the inverse square root function appeared in the source code of the game *Quake III Arena*. The operator `>>` shifts the bits in the underlying representation over by 1 position, and `reinterpret` creates a new instance of the given type whose bits are the same as the bits of the given value.\n",
    "\n",
    "```julia\n",
    "    function invsquareroot(x::Float32)\n",
    "        y = 0x5f3759df - (reinterpret(Int32,x) >> 1)\n",
    "        z = reinterpret(Float32,y)\n",
    "        z * (1.5f0 - (0.5f0*x)*z*z)\n",
    "    end\n",
    "```\n",
    "\n",
    "If you are amazed by the appearance of the magic constant `0x5f3759df` (*Side Note*: this is syntax for an unsigned, 32-bit integer) so was the original author. You can see their code comments on the Wikipedia entry for Fast Inverse Square Root:\n",
    "https://en.wikipedia.org/wiki/Fast_inverse_square_root\n",
    "\n",
    "Evaluate this function with a few input values and determine its relative error on each. Define another function which calculates the inverse square root in the obvious way (`1/sqrt(x)`) and check that the one above actually does run faster. As a double extra bonus, figure out why this code works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernel_info": {
   "name": "julia-1.1"
  },
  "kernelspec": {
   "display_name": "Julia 1.1.1",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.1"
  },
  "nteract": {
   "version": "0.15.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
