{"cells": [{"cell_type": "markdown", "metadata": {"id": "Qh2IPF4Mv9E9"}, "source": ["# Homework 10\n", "## Brown University\n", "## DATA 1010\n", "## Fall 2020"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Problem 1"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Go to `https://prismia.chat/gallery` and check out the decision tree manipulative (this is the same one we used in class).\n", "\n", "(a) Drag all of the red points into the middle and the blue points equally split to the left and right (so that, left to right in order, you encounter five blues, then 10 reds, and then the other five blues). The projections of the points onto a vertical axis should be all mixed up. Does a greedily-trained decision tree end up with training accuracy of 100% for this example? (Note: you should think about the full CART algorithm, where there is no restriction on whether each split is horizontal or vertical, rather than the restricted one in the manipulative which only allows vertical splits at the first stage and horizontal ones at the second.)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["(b) Come up with a configuration of the 10 red and 10 blue points where you can achieve 100% training accuracy (and where you would also anticipate having a high test accuracy as well), but where the greedy algorithm gives worse results."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Problem 2"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Go to `https://prismia.chat/gallery` and check out the neural network manipulative (this is the same one we used in class).\n", "\n", "(a) Starting from the good configuration of weights, biases, and input coordinates (click 'show best' to get that), move the middle bias dial all the way to the left (middle neuron in the middle column). Wiggle the sliders which govern the weights of the edges feeding into that neuron. What are the derivatives of the predicted gold probabilty (post-softmax) with respect to those two weights?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["(b) Suppose that both biases in the last layer are both increased by the same amount. How does that affect the resulting (binary) prediction function?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["(c) Suppose you wanted to have the same binary prediction function as the one shown when you click \"show best\", but you wanted the model's *probability* predictions to soften. In other words, you'd rather that the model go less quickly from nearly 100% gold to nearly 100% purple as you move across from one side of the semicircular boundary to the other.\n", "\n", "What change could you make to the weights and biases of the network to achieve this effect?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Problem 3"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We say that a model with a deterministic training process is **scale-invariant** if the following two procedures yield the same predictions for each row of the data frame of test data:\n", "\n", "1. train the model on the training data\n", "2. evaluate the model at each test input value to obtain test predictions\n", "\n", "and\n", "\n", "1. multiply a column of the data frame of training data by a positive number\n", "2. train the model on the new training data, with the modified column\n", "3. multiply that same column of the data frame of *test* data by that same positive number\n", "4. evaluate the model at each new test input value to obtain test predictions"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Which of the models we've studied in this course are scale invariant? Be sure to address linear regression for regression problems, logistic regression for binary classification, soft- and hard-margin suppor vector machines for binary classification, and decision trees for classification or regression."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}], "metadata": {"kernelspec": {"display_name": "Julia 1.5.1", "language": "julia", "name": "julia-1.5"}, "language_info": {"file_extension": ".jl", "mimetype": "application/julia", "name": "julia", "version": "1.5.1"}}, "nbformat": 4, "nbformat_minor": 4}